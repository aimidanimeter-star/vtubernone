<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>WebAR Debug</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #222; color: white; font-family: monospace; }
        /* 映像とキャンバス */
        #input-video { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); z-index: 1; }
        #output-canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 2; }
        
        /* デバッグ・操作画面 */
        #ui-container {
            position: absolute; bottom: 0; left: 0; width: 100%; height: 30%;
            background: rgba(0, 0, 0, 0.8); z-index: 10; padding: 10px; box-sizing: border-box;
            overflow-y: scroll; pointer-events: auto;
        }
        #status { font-weight: bold; color: #0f0; margin-bottom: 5px; }
        .log-entry { border-bottom: 1px solid #444; font-size: 12px; padding: 2px 0; }
        .error { color: #f55; }
        
        /* スタートボタン */
        #start-btn {
            position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%);
            padding: 20px 40px; background: #007AFF; color: white; font-size: 18px; border: none;
            border-radius: 10px; z-index: 20; cursor: pointer;
        }
    </style>
</head>
<body>
    <button id="start-btn" onclick="startApp()">ARを開始する</button>

    <video id="input-video" playsinline muted autoplay></video>
    <canvas id="output-canvas"></canvas>

    <div id="ui-container">
        <div id="status">待機中...</div>
        <div id="logs"></div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/three@0.146.0/build/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.146.0/examples/js/loaders/GLTFLoader.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@0.6.11/lib/three-vrm.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/kalidokit@1.1.5/dist/kalidokit.umd.js"></script>

    <script>
        // --- ログ機能 ---
        function log(msg, isError = false) {
            const logs = document.getElementById('logs');
            const entry = document.createElement('div');
            entry.className = isError ? 'log-entry error' : 'log-entry';
            entry.textContent = `[${new Date().toLocaleTimeString()}] ${msg}`;
            logs.prepend(entry); // 新しいものを上に
            console.log(msg);
        }
        function setStatus(msg) { document.getElementById('status').innerText = msg; }

        // --- 設定 ---
        const VRM_PATH = './model.vrm'; // ※ここが重要！

        let currentVrm = null;
        const videoElement = document.getElementById('input-video');
        const canvasElement = document.getElementById('output-canvas');
        let faceMesh = null;
        let cameraUtils = null;

        // 3D初期化
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(30.0, window.innerWidth / window.innerHeight, 0.1, 20.0);
        camera.position.set(0, 1.4, 1.5);
        const renderer = new THREE.WebGLRenderer({ canvas: canvasElement, alpha: true, antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        const light = new THREE.DirectionalLight(0xffffff);
        light.position.set(1.0, 1.0, 1.0).normalize();
        scene.add(light);

        // アニメーションループ
        const clock = new THREE.Clock();
        function animate() {
            requestAnimationFrame(animate);
            const delta = clock.getDelta();
            if (currentVrm) currentVrm.update(delta);
            renderer.render(scene, camera);
        }
        animate();

        // アプリ開始処理
        async function startApp() {
            document.getElementById('start-btn').style.display = 'none';
            setStatus("初期化中...");
            log("開始ボタンが押されました");

            // 1. VRMロード
            log(`モデル読み込み開始: ${VRM_PATH}`);
            const loader = new THREE.GLTFLoader();
            loader.load(
                VRM_PATH,
                (gltf) => {
                    THREE.VRM.from(gltf).then((vrm) => {
                        scene.add(vrm.scene);
                        currentVrm = vrm;
                        vrm.scene.rotation.y = Math.PI;
                        vrm.scene.position.y = -0.5;
                        log("VRMモデル読み込み成功！");
                        setStatus("モデルOK -> カメラ起動中...");
                        startCamera();
                    });
                },
                (progress) => { /* 進捗 */ },
                (error) => {
                    log(`VRM読み込みエラー！ファイル名を確認してください: ${error}`, true);
                    setStatus("エラー発生");
                }
            );
        }

        // 2. カメラとAIの起動
        function startCamera() {
            try {
                faceMesh = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
                faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });
                faceMesh.onResults(onResults);

                cameraUtils = new Camera(videoElement, {
                    onFrame: async () => { await faceMesh.send({image: videoElement}); },
                    width: 1280, height: 720
                });
                cameraUtils.start()
                    .then(() => log("カメラ起動成功"))
                    .catch(e => log("カメラ起動失敗: " + e, true));
            } catch (e) {
                log("ライブラリエラー: " + e, true);
            }
        }

        // 3. トラッキング処理
        function onResults(results) {
            setStatus("動作中 (顔認識待ち)");
            if (!currentVrm || !results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) return;
            
            setStatus("動作中 (トラッキング中)");
            const landmarks = results.multiFaceLandmarks[0];
            const solver = Kalidokit.Face.solve(landmarks, { runtime: "mediapipe", video: videoElement });

            if (solver) {
                const rigRotation = solver.head;
                const headBone = currentVrm.humanoid.getBoneNode(THREE.VRMSchema.HumanoidBoneName.Head);
                if(headBone) {
                    headBone.rotation.set(-rigRotation.x, -rigRotation.y, -rigRotation.z);
                }
                
                // 口と目
                const rigFace = solver.mouth;
                const preset = THREE.VRMSchema.BlendShapePresetName;
                currentVrm.blendShapeProxy.setValue(preset.A, rigFace.shape.A || 0);
                
                const blinkL = 1 - (solver.eye.l || 1);
                const blinkR = 1 - (solver.eye.r || 1);
                currentVrm.blendShapeProxy.setValue(preset.BlinkL, blinkL);
                currentVrm.blendShapeProxy.setValue(preset.BlinkR, blinkR);
            }
        }
    </script>
</body>
</html>
