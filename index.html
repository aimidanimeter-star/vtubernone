<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>WebAR VRM 1.0 Fix</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #000; }
        #video { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); z-index: 1; }
        #canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 2; pointer-events: none; }
        
        /* デバッグ表示 */
        #debug {
            position: absolute; top: 10px; left: 10px; width: 90%; 
            background: rgba(255, 0, 0, 0.7); color: white; padding: 10px; 
            z-index: 100; font-family: monospace; font-size: 14px;
            pointer-events: none; display: none; /* エラー時のみ表示 */
        }
        #status {
            position: absolute; bottom: 20px; left: 10px; color: #0f0; 
            z-index: 100; font-weight: bold; text-shadow: 1px 1px 0 #000;
        }
    </style>
    
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.169.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.169.0/examples/jsm/",
                "@pixiv/three-vrm": "https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3.0.0/lib/three-vrm.module.js"
            }
        }
    </script>
</head>
<body>
    <div id="debug"></div>
    <div id="status">初期化中...</div>
    <video id="video" playsinline muted autoplay></video>
    <canvas id="canvas"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/kalidokit@1.1.5/dist/kalidokit.umd.js"></script>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';

        // ==========================================
        // 設定：ファイル名を絶対に間違えないでください
        // ==========================================
        const MODEL_FILENAME = 'model.vrm'; 
        // ==========================================

        const debugEl = document.getElementById('debug');
        const statusEl = document.getElementById('status');
        function showError(msg) {
            debugEl.style.display = 'block';
            debugEl.innerHTML += `ERROR: ${msg}<br>`;
            statusEl.innerText = "エラー発生";
        }
        function log(msg) { statusEl.innerText = msg; console.log(msg); }

        // 1. シーン設定
        const renderer = new THREE.WebGLRenderer({ canvas: document.getElementById('canvas'), alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);

        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(30.0, window.innerWidth / window.innerHeight, 0.1, 20.0);
        camera.position.set(0, 1.4, 1.2); // 少しカメラ位置を調整

        const light = new THREE.DirectionalLight(0xffffff, 1.0);
        light.position.set(1.0, 1.0, 1.0).normalize();
        scene.add(light);

        let currentVrm = null;

        // 2. VRM読み込み (VRM1.0対応)
        const loader = new GLTFLoader();
        loader.register((parser) => new VRMLoaderPlugin(parser));

        log(`モデル(${MODEL_FILENAME})を読み込んでいます...`);

        loader.load(
            `./${MODEL_FILENAME}`,
            (gltf) => {
                const vrm = gltf.userData.vrm;
                VRMUtils.removeUnnecessaryVertices(gltf.scene);
                VRMUtils.combineSkeletons(gltf.scene);
                vrm.scene.rotation.y = Math.PI; // 後ろを向いているので反転
                
                scene.add(vrm.scene);
                currentVrm = vrm;
                log("モデル読み込み成功！カメラ起動中...");
                startCamera();
            },
            (progress) => {
                const per = Math.round(100.0 * (progress.loaded / progress.total));
                log(`ロード中... ${per}%`);
            },
            (error) => {
                console.error(error);
                showError(`モデルが見つかりません。<br>GitHubのファイル名が <b>${MODEL_FILENAME}</b> と完全に一致しているか確認してください。<br>(Model.vrm や model.VRM はダメです)`);
            }
        );

        // 3. アニメーションループ
        const clock = new THREE.Clock();
        function animate() {
            requestAnimationFrame(animate);
            if (currentVrm) {
                currentVrm.update(clock.getDelta());
            }
            renderer.render(scene, camera);
        }
        animate();

        // 4. カメラと顔認識
        const videoElement = document.getElementById('video');
        
        function onResults(results) {
            if (!currentVrm) return;
            if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {
                log("顔を探しています...");
                return;
            }
            log("トラッキング中");

            const landmarks = results.multiFaceLandmarks[0];
            const solver = Kalidokit.Face.solve(landmarks, { runtime: "mediapipe", video: videoElement });

            if (solver) {
                // 回転
                const rigRotation = solver.head;
                // VRM 1.0 では humanoid.getRawBoneNode などを適宜使うが、
                // 簡易的にヒューマノイドボーンを操作
                const head = currentVrm.humanoid.getNormalizedBoneNode('head');
                if(head) {
                    head.rotation.set(-rigRotation.x, -rigRotation.y, -rigRotation.z);
                }

                // 表情
                const rigFace = solver.mouth;
                // VRM 1.0のExpressionManager対応 (古いBlendShapeProxyとは違う)
                if (currentVrm.expressionManager) {
                    const preset = 'aa'; // VRM1.0の 'aa' (あ)
                    const open = rigFace.shape.A || 0;
                    currentVrm.expressionManager.setValue(preset, open);
                    
                    // まばたき
                    const blinkL = 1 - (solver.eye.l || 1);
                    const blinkR = 1 - (solver.eye.r || 1);
                    currentVrm.expressionManager.setValue('blinkLeft', blinkL);
                    currentVrm.expressionManager.setValue('blinkRight', blinkR);
                }
            }
        }

        const faceMesh = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
        faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });
        faceMesh.onResults(onResults);

        function startCamera() {
            const camera = new Camera(videoElement, {
                onFrame: async () => { await faceMesh.send({image: videoElement}); },
                width: 1280, height: 720
            });
            camera.start();
        }

        // リサイズ対応
        window.addEventListener('resize', () => {
            renderer.setSize(window.innerWidth, window.innerHeight);
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
        });
    </script>
</body>
</html>
