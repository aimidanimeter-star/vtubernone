<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>WebAR Final Fix</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #000; }
        #video { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; transform: scaleX(-1); z-index: 1; }
        #canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 2; pointer-events: none; }
        /* 状態表示 */
        #status-box {
            position: absolute; top: 10px; left: 10px; width: 90%;
            padding: 10px; background: rgba(0, 0, 0, 0.7); color: #0f0;
            font-family: monospace; font-size: 16px; z-index: 100; pointer-events: none;
        }
        .error-text { color: #ff4444; font-weight: bold; }
    </style>
    <script type="importmap">
    {
        "imports": {
            "three": "https://cdn.jsdelivr.net/npm/three@0.169.0/build/three.module.js",
            "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.169.0/examples/jsm/",
            "@pixiv/three-vrm": "https://cdn.jsdelivr.net/npm/@pixiv/three-vrm@3.0.0/lib/three-vrm.module.js"
        }
    }
    </script>
</head>
<body>
    <div id="status-box">初期化中...</div>
    <video id="video" playsinline muted autoplay></video>
    <canvas id="canvas"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/kalidokit@1.1.5/dist/kalidokit.umd.js"></script>

    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { VRMLoaderPlugin, VRMUtils } from '@pixiv/three-vrm';

        // ==========================================
        const MODEL_FILENAME = 'model.vrm'; 
        // ==========================================

        const statusEl = document.getElementById('status-box');
        function log(msg, isError = false) {
            statusEl.innerHTML = msg;
            statusEl.className = isError ? 'error-text' : '';
            console.log(msg);
        }

        // 1. シーン設定
        const renderer = new THREE.WebGLRenderer({ canvas: document.getElementById('canvas'), alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.setPixelRatio(window.devicePixelRatio);
        // ★重要: 2021年モデル用の色補正
        renderer.outputColorSpace = THREE.SRGBColorSpace; 

        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(35.0, window.innerWidth / window.innerHeight, 0.1, 20.0);
        camera.position.set(0, 1.4, 1.8); // カメラ位置調整

        // 明るめのライト（古いモデルが暗くならないように）
        const light = new THREE.DirectionalLight(0xffffff, 1.5);
        light.position.set(0, 0, 1).normalize();
        scene.add(light);
        const ambient = new THREE.AmbientLight(0xffffff, 0.8);
        scene.add(ambient);

        let currentVrm = null;

        // 2. モデル読み込み
        log(`モデル ${MODEL_FILENAME} を読み込み中...`);
        const loader = new GLTFLoader();
        loader.register((parser) => new VRMLoaderPlugin(parser));

        loader.load(
            `./${MODEL_FILENAME}`,
            (gltf) => {
                const vrm = gltf.userData.vrm;
                VRMUtils.removeUnnecessaryVertices(gltf.scene);
                VRMUtils.combineSkeletons(gltf.scene);
                
                // ★重要: VRM0.0(2021年版)の回転補正
                vrm.scene.rotation.y = Math.PI; 

                scene.add(vrm.scene);
                currentVrm = vrm;
                log("モデル読み込み成功！顔認識を開始します...");
                startCamera();
            },
            (progress) => {
                const per = progress.total > 0 ? Math.round(100 * progress.loaded / progress.total) + '%' : '...';
                log(`ロード中: ${per}`);
            },
            (error) => {
                console.error(error);
                // エラーなら赤い箱を出す（絶対何かを表示させる）
                const box = new THREE.Mesh(new THREE.BoxGeometry(0.3, 0.3, 0.3), new THREE.MeshBasicMaterial({ color: 0xff0000 }));
                box.position.set(0, 1.4, 0);
                scene.add(box);
                log(`エラー: ${MODEL_FILENAME} が読み込めませんでした。<br>代わりに赤い箱を出します。<br>原因: ${error.message}`, true);
            }
        );

        // 3. アニメーション
        const clock = new THREE.Clock();
        function animate() {
            requestAnimationFrame(animate);
            if (currentVrm) currentVrm.update(clock.getDelta());
            renderer.render(scene, camera);
        }
        animate();

        // 4. 顔認識
        const videoElement = document.getElementById('video');
        
        function onResults(results) {
            if (!currentVrm) return;
            
            if (!results.multiFaceLandmarks || results.multiFaceLandmarks.length === 0) {
                // 顔が見つからない時
                return;
            }
            
            // ここで前回のバグを修正
            const landmarks = results.multiFaceLandmarks[0];
            const solver = Kalidokit.Face.solve(landmarks, { runtime: "mediapipe", video: videoElement });

            if (solver) {
                // ★ここが修正箇所
                const rigRotation = solver.head; 
                const head = currentVrm.humanoid.getNormalizedBoneNode('head');
                if(head) {
                    head.rotation.set(-rigRotation.x, -rigRotation.y, -rigRotation.z);
                }

                // 表情
                if (currentVrm.expressionManager) {
                    currentVrm.expressionManager.setValue('aa', solver.mouth.shape.A || 0);
                    currentVrm.expressionManager.setValue('blinkLeft', 1 - (solver.eye.l || 1));
                    currentVrm.expressionManager.setValue('blinkRight', 1 - (solver.eye.r || 1));
                }
            }
        }

        async function startCamera() {
            const faceMesh = new FaceMesh({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`});
            faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5, minTrackingConfidence: 0.5 });
            faceMesh.onResults(onResults);

            const camera = new Camera(videoElement, {
                onFrame: async () => { await faceMesh.send({image: videoElement}); },
                width: 1280, height: 720
            });
            await camera.start();
            log("準備完了！顔を動かしてください");
        }

        window.addEventListener('resize', () => {
            renderer.setSize(window.innerWidth, window.innerHeight);
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
        });
    </script>
</body>
</html>
